{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-vqHHuE_U5W"
      },
      "source": [
        "# HW 1. Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3PhLKG01mF7y"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6BdW91v_cNa"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Для того чтобы загрузить данные в нейросеть или более простые алгоритмы ML, их необходимо должным образом открыть и преобразовать в вектор с числами. Для этого воспользуемся функцией ```read_files()```.\n",
        "\n",
        "Этот парсер делает следующие вещи:\n",
        " - открывает файл картинки с диска (с помощью библиотеки opencv),\n",
        " - проверяет, что картинка действительно открылась и сейчас является матрицей (```np.array```),\n",
        " - преобразует матрицу в вектор (путем записи всех столбцов друг под другом),\n",
        " - возвращает массив из векторов, в которых хранятся картинки, и лейбл, соответствующий каждой картинке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZhJZszn4FAhG"
      },
      "outputs": [],
      "source": [
        "def read_files(path: str, ans: int, target_dim: tuple = (256, 256)):\n",
        "    files = os.listdir(path)\n",
        "    X = None\n",
        "    for i, name in enumerate(files):\n",
        "        img = cv2.imread(path + '/' + name, 0) # 0 means black-white picture\n",
        "        if img.shape != 0:\n",
        "            img = cv2.resize(img, target_dim)\n",
        "            vect = img.reshape(1, 256 ** 2) / 255.\n",
        "\n",
        "            X = vect if (X is None) else np.vstack((X, vect))\n",
        "        # print(f\"{i}/{len(files)}\")\n",
        "    # print()\n",
        "    y = np.ones((len(files))) * ans\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Crs3tfd9OV"
      },
      "source": [
        "Логика программы следующая:\n",
        " - есть класс ```LogisticRegression```. Он содержит веса модели и нужен для того, чтобы генерировать предсказания. Также, этот класс снабжен методом backward() для возможности дифференцирования функции потерь по весам этого класса.\n",
        " - есть класс ```Loss```. Он определяет функцию потерь, которую мы хотим использовать. Также, этот класс осуществляет подсчет градиентов функции потерь по всем весам модели.\n",
        " - есть класс ```Optimizer```. Он отвечает за то, как будут обновляться веса после подсчета градиентов (после работы класса ```Loss```). Сегодня мы рассматриваем простой градиентный спуск, но более сложные модели используют более усовершенствованные алгоритмы оптимизации.\n",
        "\n",
        "То есть:\n",
        " 1. Вызывается метод ```forward()``` нашей модели (логистической регрессии). После этого у нас выводятся текущие предсказания модели.\n",
        " 2. Вызывается метод ```loss()```, который сравнивает предсказания модели с истинными ответами. После этого подсчитываются градиенты функции потерь по всем весам модели.\n",
        " 3. Подсчитанные градиенты вычитаются из весов (происходит шаг градиентного спуска) путем вызова ```optimizer.step()```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Логистическая регрессия. Backward propagation\n",
        "Back propagation реализуется с помощью уравнений, написанных ниже. Для подсчитанной функции потерь:\n",
        "$$\n",
        "\\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^{m} y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\n",
        "$$\n",
        "где $\\hat{y}_i = \\sigma(w^T x_i + b)$, где $\\sigma$ - сигмоидная функция.\n",
        "\n",
        "После длительных вычислений, мы получаем, что:\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial w} = \\frac{1}{m} X^T (\\hat{y} - y)\n",
        "$$\n",
        "$$\n",
        "\\frac{\\partial \\mathcal{L}}{\\partial b} = \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)\n",
        "$$\n",
        "Таким образом, мы можем обновить веса модели с помощью градиентного спуска:\n",
        "$$\n",
        "w = w - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial w} = w - \\alpha \\frac{1}{m} X^T (\\hat{y} - y)\n",
        "$$\n",
        "$$\n",
        "b = b - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial b}  = b - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (\\hat{y}_i - y_i)\n",
        "$$\n",
        "где $\\alpha$ - скорость обучения (learning_rate).   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sAgudbjuBzjo"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, n_features):\n",
        "        self.w = np.zeros(n_features)\n",
        "        self.b = 0.0\n",
        "\n",
        "    def forward(self, X):\n",
        "        z = np.dot(X, self.w) + self.b\n",
        "        return self.sigmoid(z)\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z))\n",
        "    \n",
        "class Loss:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, y_pred, y_true):\n",
        "        eps= 1e-15  # Малое значение для предотвращения ошибок логарифма\n",
        "        y_pred = np.clip(y_pred, eps, 1 - eps)  # Ограничение значений\n",
        "        loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "        return np.mean(loss)\n",
        "\n",
        "    def backward(self, y_pred, y, X):\n",
        "        dz = y_pred - y\n",
        "        dw = np.dot(X.T, dz) / len(y)\n",
        "        db = np.mean(dz)      \n",
        "        return dw, db\n",
        "\n",
        "class Optimizer:\n",
        "    def __init__(self, learning_rate):\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def step(self, model, dw, db):\n",
        "        model.w -= self.learning_rate * dw\n",
        "        model.b -= self.learning_rate * db"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9cVot29-iu"
      },
      "source": [
        "# Задание\n",
        "\n",
        "1. Загрузить датасет, разбить его на два датасета: первый для обучения, второй - для проверки качества (см. функцию [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
        "2. Посчитать производные функции потерь по w и по b\n",
        "3. Реализовать цикл обучения, обновляя параметры логистической регрессии:\n",
        "$$w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$\n",
        "<!-- <br> -->\n",
        "$$b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$\n",
        "Обратите внимание на величину $\\alpha$. Ее надо подобрать, иначе алгоритм не будет обучаться.\n",
        "\n",
        "4. Посчитать финальное качество модели по метрике [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эпоха 0, loss: 0.6931\n",
            "Эпоха 10, loss: 0.1727\n",
            "Эпоха 20, loss: 0.1291\n",
            "Эпоха 30, loss: 0.1042\n",
            "Эпоха 40, loss: 0.0870\n",
            "Эпоха 50, loss: 0.0744\n",
            "Эпоха 60, loss: 0.0647\n",
            "Эпоха 70, loss: 0.0571\n",
            "Эпоха 80, loss: 0.0510\n",
            "Эпоха 90, loss: 0.0460\n",
            "Точность на тестовой выборке: 1.0000\n"
          ]
        }
      ],
      "source": [
        "path_to_box = 'lesson1_dataset/box' \n",
        "path_to_no_box = 'lesson1_dataset/no_box'\n",
        "\n",
        "X_box, y_box = read_files(path_to_box, ans=1)\n",
        "X_no_box, y_no_box = read_files(path_to_no_box, ans=0)\n",
        "\n",
        "X = np.vstack((X_box, X_no_box))\n",
        "y = np.concatenate((y_box, y_no_box), axis=0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "model = LogisticRegression(input_size)\n",
        "loss_function = Loss()\n",
        "optimizer = Optimizer(learning_rate=0.01) #  меняем это\n",
        "\n",
        "num_epochs = 100 # меняем это\n",
        "for epoch in range(num_epochs):\n",
        "    # forward propagation\n",
        "    y_pred = model.forward(X_train)\n",
        "\n",
        "    # backward propagation\n",
        "    loss = loss_function(y_pred, y_train)\n",
        "    dw, db = loss_function.backward(y_pred, y_train, X_train)\n",
        "\n",
        "    # Обновление весов\n",
        "    optimizer.step(model, dw, db)\n",
        "\n",
        "    # Вывод значений потерь (каждую 10-ю эпоху)\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Эпоха {epoch}, loss: {loss:.4f}\")\n",
        "\n",
        "y_pred_test = model.forward(X_test)\n",
        "y_pred_class = (y_pred_test > 0.5).astype(int)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred_class)\n",
        "print(f\"Точность на тестовой выборке: {accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
