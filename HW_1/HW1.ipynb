{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-vqHHuE_U5W"
      },
      "source": [
        "# HW 1. Логистическая регрессия"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PhLKG01mF7y"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6BdW91v_cNa"
      },
      "source": [
        "## Загрузка данных\n",
        "\n",
        "Для того чтобы загрузить данные в нейросеть или более простые алгоритмы ML, их необходимо должным образом открыть и преобразовать в вектор с числами. Для этого воспользуемся функцией ```read_files()```.\n",
        "\n",
        "Этот парсер делает следующие вещи:\n",
        " - открывает файл картинки с диска (с помощью библиотеки opencv),\n",
        " - проверяет, что картинка действительно открылась и сейчас является матрицей (```np.array```),\n",
        " - преобразует матрицу в вектор (путем записи всех столбцов друг под другом),\n",
        " - возвращает массив из векторов, в которых хранятся картинки, и лейбл, соответствующий каждой картинке."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZhJZszn4FAhG"
      },
      "outputs": [],
      "source": [
        "def read_files(path: str, ans: int, target_dim: tuple = (256, 256)):\n",
        "    files = os.listdir(path)\n",
        "    X = None\n",
        "    for i, name in enumerate(files):\n",
        "        img = cv2.imread(path + '/' + name, 0) # 0 means black-white picture\n",
        "        if img.shape != 0:\n",
        "            img = cv2.resize(img, (256, 256))\n",
        "            vect = img.reshape(1, 256 ** 2) / 255.\n",
        "\n",
        "            X = vect if (X is None) else np.vstack((X, vect))\n",
        "        print(f\"{i}/{len(files)}\")\n",
        "    print()\n",
        "    y = np.ones((len(X),1)) * ans\n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0Crs3tfd9OV"
      },
      "source": [
        "Логика программы следующая:\n",
        " - есть класс ```LogisticRegression```. Он содержит веса модели и нужен для того, чтобы генерировать предсказания. Также, этот класс снабжен методом backward() для возможности дифференцирования функции потерь по весам этого класса.\n",
        " - есть класс ```Loss```. Он определяет функцию потерь, которую мы хотим использовать. Также, этот класс осуществляет подсчет градиентов функции потерь по всем весам модели.\n",
        " - есть класс ```Optimizer```. Он отвечает за то, как будут обновляться веса после подсчета градиентов (после работы класса ```Loss```). Сегодня мы рассматриваем простой градиентный спуск, но более сложные модели используют более усовершенствованные алгоритмы оптимизации.\n",
        "\n",
        "То есть:\n",
        " 1. Вызывается метод ```forward()``` нашей модели (логистической регрессии). После этого у нас выводятся текущие предсказания модели.\n",
        " 2. Вызывается метод ```loss()```, который сравнивает предсказания модели с истинными ответами. После этого подсчитываются градиенты функции потерь по всем весам модели.\n",
        " 3. Подсчитанные градиенты вычитаются из весов (происходит шаг градиентного спуска) путем вызова ```optimizer.step()```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAgudbjuBzjo"
      },
      "outputs": [],
      "source": [
        "class LogisticRegression:\n",
        "    def __init__(self, n_features):\n",
        "        pass\n",
        "\n",
        "\n",
        "    def predict(self, X: np.array):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH9cVot29-iu"
      },
      "source": [
        "# Задание\n",
        "\n",
        "1. Загрузить датасет, разбить его на два датасета: первый для обучения, второй - для проверки качества (см. функцию [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html))\n",
        "2. Посчитать производные функции потерь по w и по b\n",
        "3. Реализовать цикл обучения, обновляя параметры логистической регрессии:\n",
        "$$w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$\n",
        "<br>\n",
        "$$b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$\n",
        "Обратите внимание на величину $\\alpha$. Ее надо подобрать, иначе алгоритм не будет обучаться.\n",
        "4. Посчитать финальное качество модели по метрике [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
